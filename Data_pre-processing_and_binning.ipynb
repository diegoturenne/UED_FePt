{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "#width for some images\n",
    "im_width = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib nbagg\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patch\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "plt.rcParams['xtick.minor.visible'] = True\n",
    "plt.rcParams['ytick.minor.visible'] = True\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "# import scipy.optimize \n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.misc import face\n",
    "from scipy import interpolate\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import sys \n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import h5py\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import socket  \n",
    "import itertools\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import cv2\n",
    "\n",
    "udir = '/cds/home/d/diegotur/UED/'\n",
    "\n",
    "if udir not in sys.path:\n",
    "    sys.path.append(udir)\n",
    "\n",
    "import ued_dt3 as ued_dt\n",
    "try:\n",
    "    import pyFAI, pyFAI.detectors\n",
    "    from pyFAI.azimuthalIntegrator import AzimuthalIntegrator\n",
    "except:\n",
    "    print('No pyFAI library found. If you want to do azimuthal integrations - install it!')\n",
    "\n",
    "import dt_functions as dt\n",
    "import I_UED_dt\n",
    "\n",
    "\n",
    "import lmfit\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp.reload(ued_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Select Runs and ROIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls '/cds/group/ued/data/ueduu0701/FePt/20190715/Run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [\n",
    "# # Sample A-1\n",
    "#     ANDOR1_delay_001_29.85995800_0001.tif\n",
    "#     ANDOR1_delayLong-001-234.64039900_20191123_230616.790989_943427176.79_0001.tif\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_2326/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_2358/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0117/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0324/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0530/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0736/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0942/', # position nb2 2.4mJ\n",
    "#     '/cds/group/ued/data/ueduu1901/FePt/20190708/Run/20190708_1942/',\n",
    "#     '/cds/group/ued/data/ueduu1901/FePt/20190708/Run/20190708_2009/'\n",
    "#     '/cds/group/ued/data/ueduu1901/FePt/20190711/Run/20190711_1905/'\n",
    "    \n",
    "    \n",
    "    #### New data by diego \n",
    "    \n",
    "    ##Sample Durr #5 (UED)\n",
    "#     '/cds/group/ued/data/ueduu1901/FePt/20190711/Run/20190711_2034/'  #  Durr#5, Fluence = 3 mJ/cm^2\n",
    "#     '/cds/group/ued/data/ueduu1901/FePt/20190711/Run/20190711_2353/',  #  Durr#5, Fluence = 6 mJ/cm^2\n",
    "#     '/cds/group/ued/data/ueduu1901/FePt/20190711/Run/20190711_2034/',  #  Durr#5, Fluence = 6 mJ/cm^2\n",
    "    \n",
    "    ## Sample Reid#3 7nm NPs \n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190712/Run/20190712_1212/',  #   Reid#3, Fluence = 3 mJ/cm^2 (1st diffuse_scan)\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190712/Run/20190712_1743/',  #   Reid#3, Fluence = 3 mJ/cm^2 (short scan for t0)\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190712/Run/20190712_1801/',  #   Reid#3, Fluence = 3 mJ/cm^2 (diffuse_scan)\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190712/Run/20190712_2220/',  #   Reid#3, Fluence = 4 mJ/cm^2 (timescan) run 11\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190712/Run/20190712_2257/',  #   Reid#3, Fluence = 4 mJ/cm^2 (timescan) run 12\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_0605/',  #   Reid#3, Fluence = 3 mJ/cm^2 (diffuse) run 13 new spot\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_1132/',  #   Reid#3, Fluence = 4 mJ/cm^2 (diffuse) run 14 klystron went kaput\n",
    "#       '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_1959/',  #   Reid#3, Fluence = 4 mJ/cm^2 (timescan) run 19  (15min)\n",
    "      '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021/',  #   Reid#3, Fluence = 4 mJ/cm^2 (diffuse) run 20  (2 days)\n",
    "      '/cds/group/ued/data/ueduu0701/FePt/20190715/Run/20190715_0252/',  #   Reid#3, Fluence = 4 mJ/cm^2 (diffuse) run ???  )\n",
    "\n",
    "    \n",
    "    #############################################\n",
    "    ####   November part of the beamtime      ###\n",
    "    #############################################\n",
    "    \n",
    "    ## Sample 6-1 (16nm NPs)     \n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_1251/',  #   6-1, run 20  Fluence = 4 mJ/cm^2 fluence damage scan\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_1358/',  #   6-1, run 33  Fluence = 12 mJ/cm^2 fluence (30 min)\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_1535/',  #   6-1, run 34  Fluence = 12 mJ/cm^2 fluence (45 min) ( new spot)\n",
    "    \n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_1618/',  #   6-1, run 35  Fluence = 6 mJ/cm^2 fluence (20 min)\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_1735/',  #   6-1, run 36  Fluence = 6 mJ/cm^2 fluence (20 min)\n",
    "\n",
    "    ###### Sample 6-2 (16nm NPs)  45 deg NOVEMBER \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1130/',  # 6-2 run 62 TEST 2.4 mJ/cm2 45 deg\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1316/',  # 6-2 run 63 TEST 4.2 mJ/cm2  45 deg \n",
    "    ###### \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_2123/',  # 6-2 run 63  4.2 mJ/cm2 1.5 hr\n",
    "\n",
    "    \n",
    "    ## Sample A-5 (7nm NPs)    \n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_2031/',  #   A-5, run 40  Fluence = 4 mJ/cm^2 fluence (1hr )\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_2146/',  #   A-5, run 41  Fluence = 3.3 mJ/cm^2 fluence (20min)\n",
    "\n",
    "    ## Sample A-7 (7nm NPs)    \n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191121/Run/20191121_2216/',  #   A-7, run 42  Fluence = 4 mJ/cm^2 fluence (3 hr ) DIFFUSE \n",
    "    \n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_0559/',  #   A-7, run 45  Fluence = 3.3 mJ/cm^2 fluence (1 hr) differnet position \n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_0655/',  #   A-7, run 46  Fluence = 3.3* mJ/cm^2 fluence (1 hr)\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_0810/',  #   A-7, run 47  Fluence = 3.3* mJ/cm^2 fluence (3 hrs)  \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_1528/',  #   A-7, run 51  Fluence = 2.4 mJ/cm^2 fluence (20 min)\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_1543/',  #   A-7, run 52  Fluence = 2.83 mJ/cm^2 fluence (1 hr)\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_1739/',  #   A-7, run 55  Fluence = 2.83 mJ/cm^2 fluence (1 hr) second position\n",
    "\n",
    "#          '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1603/',  #   A-7, run 64  Fluence = 2.8 mJ/cm^2 fluence (20min) third position t0 slighlty shifted \n",
    "#          '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1619/',  #   A-7, run 65  Fluence = 2.8 mJ/cm^2 fluence (20min) third position t0 slighlty shifted \n",
    "#          '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1636/',  #   A-7, run 66  Fluence = 2.8 mJ/cm^2 fluence (10min) third position t0 slighlty shifted \n",
    "    \n",
    "#          '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1724/',  #   A-7, run 67  Fluence = 1.5 mJ/cm^2 fluence (1.5hr) third position t0 slighlty shifted \n",
    "#          '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1909/',  #   A-7, run 68  Fluence = 1.5 mJ/cm^2 fluence (1.0hr) third position t0 slighlty shifted \n",
    "\n",
    "\n",
    "    ## Sample A-4 (7nm NPs)\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_0116/',  #   A-4, run 43  Fluence = 4 mJ/cm^2 fluence (1hr )\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_0222/',  #   A-4, run 44  Fluence = 2.48* mJ/cm^2 fluence (3.5 hrs )\n",
    "    \n",
    "##        #'/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_1059/',  #   A-4, run 48  Fluence = 2.83 mJ/cm^2 fluence (3 hrs)***CANCELED\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_1124/',  #   A-4, run 49  Fluence = 2.4 mJ/cm^2 fluence (30 min)\n",
    "#        '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_1152/',  #   A-4, run 50  Fluence = 2.4 mJ/cm^2 fluence (2 hrs)\n",
    "    \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191122/Run/20191122_2051/',  #   A-4, run 56  Fluence = 2.4 mJ/cm^2 fluence (4 hrs) second position\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_0108/',  #   A-4, run 57  Fluence = 2.4 mJ/cm^2 fluence (3 hrs) second position\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_0304/',  #   A-4, run 58  Fluence = 2.4 mJ/cm^2 fluence (2 hrs) second position\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_0504/',  #   A-4, run 59  Fluence = 2.4 mJ/cm^2 fluence (2 hrs) second position\n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_0704/',  #   A-4, run 60  Fluence = 2.4 mJ/cm^2 fluence (2 hrs) second position\n",
    "\n",
    "    \n",
    "#    ## TESTS OVERLAP \n",
    "#             '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_1022/',  # 6-1 run 61 TEST no pump-probe \n",
    "\n",
    "#    ## Sample A-1 (7nm NPs) LASTSCAN WITH LOTS OF STATISTICS \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_2305/',  #   A-1, run 73  Fluence = 2.6 mJ/cm^2 fluence (20min) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_2326/',  #   A-1, run 74  Fluence = 2.6 mJ/cm^2 fluence (30min) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191123/Run/20191123_2358/',  #   A-1, run 75  Fluence = 2.6 mJ/cm^2 fluence (1hr) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0117/',  #   A-1, run 76  Fluence = 2.6 mJ/cm^2 fluence (2hrs) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0324/',  #   A-1, run 77  Fluence = 2.6 mJ/cm^2 fluence (2hrs) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0530/',  #   A-1, run 78  Fluence = 2.6 mJ/cm^2 fluence (2hrs) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0736/',  #   A-1, run 79  Fluence = 2.6 mJ/cm^2 fluence (2hrs) \n",
    "#         '/cds/group/ued/data/ueduu0701/FePt/20191124/Run/20191124_0942/',  #   A-1, run 80  Fluence = 2.6 mJ/cm^2 fluence (2hrs) \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "#manually picked ROIs. otherwise can be picked on the images\n",
    "roinames = ['100', '010', '-100', '0-10']\n",
    "# roicoord =[\n",
    "#     [537.5647674001301-75, 415.4764844228147-25],\n",
    "#     [408.22747475890344-75, 484.8345765991508+75],\n",
    "#     [474.5968982798045, 613.1830376234469],\n",
    "#     [603.2627625972366, 543.0210908605212]\n",
    "\n",
    "# ]\n",
    "# roicoord = [ \n",
    "#     [459.9762638647842, 400.29103070307985],\n",
    "#     [376.7059909953882, 557.5494567460468],\n",
    "#     [529.8265369782005, 645.8777924608883],\n",
    "#     [613.838374144344, 489.0744582616936]\n",
    "#          ]\n",
    "\n",
    "##ROI COORDS FOR DURR#3\n",
    "# roicoord = [ \n",
    "#     [396.6312429816506, 427.61301581062247],\n",
    "#     [395.79999071815047, 605.1771073105715],\n",
    "#     [569.4199198231861, 612.4446831914642],\n",
    "#     [572.5692461206526, 429.99972161204875]\n",
    "#         ]\n",
    "\n",
    "# ##ROI COORDS FOR REID#3 (scans up to scan 6 )\n",
    "# roicoord = [ \n",
    "#     [394.9690628207779, 591.5979720784686],\n",
    "#     [416.4662550093123, 415.7681316868374],\n",
    "#     [589.54072255214, 438.3971200453235],\n",
    "#     [568.0691692532218, 618.4926064656769]\n",
    "#         ]\n",
    "# ##ROI COORDS FOR REID#3 (scans up to scan 11  )\n",
    "roicoord = [\n",
    "    [425.719203896629, 447.27946659749034],\n",
    "    [566.5981163772879, 466.7329921805848],\n",
    "    [549.3065779277509, 611.0787981335249],\n",
    "    [408.2835757825091, 589.498444929509]\n",
    "    ]\n",
    "\n",
    "\n",
    "#################################################\n",
    "###               November beamtime          ####\n",
    "#################################################\n",
    "\n",
    "\n",
    "##ROI COORDS FOR 6-1 \n",
    "# roicoord = [\n",
    "#     [409.7501221355705, 460.11673774289636],\n",
    "#     [454.33683193329637, 597.7815615838401],\n",
    "#     [591.7826497828627, 549.5697196964619],\n",
    "#     [546.8002871758365, 411.9324065317806]\n",
    "#     ]\n",
    "\n",
    "##ROI COORDS FOR 6-2\n",
    "## November 45 degree coords \n",
    "# roicoord = [\n",
    "#     [355.20606548802255, 503.8427677315243],\n",
    "#     [421.62668967881297, 401.81102615120653],\n",
    "#     [643.7411158194543, 496.3933663971188],\n",
    "#     [577.395204314611, 598.5941547627724]\n",
    "# ]\n",
    "## Normal Incidence \n",
    "# roicoord = [\n",
    "#     [430.27624514102627, 446.913022756522],\n",
    "#     [436.7527498433451, 590.8338103626909],\n",
    "#     [580.6485834587917, 581.942431924741],\n",
    "#     [574.8988012162091, 436.85979802478386]\n",
    "#     ]\n",
    "\n",
    "\n",
    "##ROI COORDS FOR A-5 \n",
    "# roicoord = [\n",
    "#     [441.8697240883871, 418.64835790226664],\n",
    "#     [399.52565800030294, 558.8879840431721],\n",
    "#     [538.212189226932, 598.333167969614],\n",
    "#     [580.1500298426822, 457.41969567839857]\n",
    "#     ]\n",
    "\n",
    "##ROI COORDS FOR A-7\n",
    "# roicoord = [\n",
    "#     [403.29727324057103, 470.23631859803555],\n",
    "#     [459.2479391646798, 602.6476108224533],\n",
    "#     [593.3621441748841, 543.1749195911908],\n",
    "#     [536.8160795964775, 409.8654825972398]\n",
    "#     ]\n",
    "\n",
    "# # ##ROI COORDS FOR A-4 ( part 1)\n",
    "# roicoord = [\n",
    "#     [396.4738147031174, 482.7610610035141],\n",
    "#     [472.10558392110414, 605.3438944336184],\n",
    "#     [595.8666165095226, 526.1048957684144],\n",
    "#     [519.808681457864, 403.71545198854676]\n",
    "#     ]\n",
    "\n",
    "# # ##ROI COORDS FOR A-4 ( part 2)\n",
    "# roicoord = [\n",
    "#     [397.90901051831287, 481.2060856910164],\n",
    "#     [473.46183062583697, 602.9358134548061],\n",
    "#     [597.3314747552948, 523.7333726459591],\n",
    "#     [520.6801893805, 401.25109004381363]\n",
    "#     ]\n",
    "\n",
    "\n",
    "# # ##ROI COORDS FOR A-1\n",
    "# roicoord = [\n",
    "#     [408.2997507402134, 484.98371044631955],\n",
    "#     [474.63955801180214, 613.2089071715462],\n",
    "#     [603.3774902914787, 543.1489158176628],\n",
    "#     [537.6127207228366, 415.5927701635615]\n",
    "#     ]\n",
    "\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# from scipy.optimize import OptimizeWarning\n",
    "# # warnings.filterwarnings(action = \"error\", category=OptimizeWarning)\n",
    "# warnings.filterwarnings(action = \"ignore\", category=OptimizeWarning)\n",
    "\n",
    "#create diffraction object\n",
    "dif = ued_dt.diffraction(sample = 'FePt 6-1 16nm', data_path = data_path, roisize=40, maxorder = '550', roicoord=roicoord, roinames = roinames, a_reference=0.336, noscans=False, skipnimages=0, plot_width=15)\n",
    "\n",
    "# try:\n",
    "#     #prepare everything for azimuthal integration\n",
    "#     dif.initialize_pyFAI(pixelsize=13e-6, sample_to_detector=7.7, e_energy=2e6, wl_correction=122.03 )\n",
    "# except:\n",
    "#     print ('AI doesn\\'t work'),\n",
    "\n",
    "dif.exposure = 6.\n",
    "dif.gain = 65.\n",
    "\n",
    "\n",
    "# 100;010;-100;0-10  MOST SCANS \n",
    "# 100;110;-100;-1-10  #45 deg \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Delete corrupted image ( and it's I0)\n",
    "corruped_image_fname =   '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021//scan074/images-ANDOR1/ANDOR1_longDelay-010-273.37897900_0001.tif'\n",
    "corruped_image_fnameI0 = '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021//scan074/I0/ANDOR2_longDelay-011-273.3790_20190714_073149.502110_0001.tif'\n",
    "# corruped_image_fnameI0 = '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021//scan074/I0/ANDOR2_longDelay-010-273.3940_20190714_073134.576158_0001.tif'\n",
    "idx_delete = np.where(dif.fnames == corruped_image_fname)\n",
    "\n",
    "dif.fnames = np.delete(dif.fnames,idx_delete)\n",
    "dif.fnames_I0 = np.delete(dif.fnames_I0,idx_delete)\n",
    "\n",
    "\n",
    "\n",
    "### Delete corrupted image ( and it's I0)\n",
    "corruped_image_fname =   '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021//scan104/images-ANDOR1/ANDOR1_longDelay-032-273.25906300_0001.tif'\n",
    "corruped_image_fnameI0 = '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021//scan074/I0/ANDOR2_longDelay-011-273.3790_20190714_073149.502110_0001.tif'\n",
    "# corruped_image_fnameI0 = '/cds/group/ued/data/ueduu0701/FePt/20190713/Run/20190713_2021//scan074/I0/ANDOR2_longDelay-010-273.3940_20190714_073134.576158_0001.tif'\n",
    "idx_delete = np.where(dif.fnames == corruped_image_fname)\n",
    "\n",
    "dif.fnames = np.delete(dif.fnames,idx_delete)\n",
    "dif.fnames_I0 = np.delete(dif.fnames_I0,idx_delete)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time zero ! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time zero\n",
    "\n",
    "dif.t0 =  273.349 #november first scans \n",
    "# dif.t0 = 29.8\n",
    "# dif.t0 = 235.21\n",
    "\n",
    "\n",
    "# load delays from filenames\n",
    "dif.load_delays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select all values pre-t0 for beam drift analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.max_frame = 25\n",
    "dif.frame_step = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sel_pre_t0 = np.where(dif.delays_ps < 0.5)\n",
    "sel_pre_t0 = np.where(dif.delays_ps < -0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_20_pre_pump = dif.load_img(dif.fnames[sel_pre_t0[0][0:20]])\n",
    "last_20_pre_pump = dif.load_img(dif.fnames[sel_pre_t0[0][-20:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the lattice and predict Bragg peak positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dif.a_reference)\n",
    "# dif.a_reference = 2.73\n",
    "# print(dif.a_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.allBragg_coord_1, dif.allBragg_names_1, dif.allBragg_indices_1 = ued_dt.find_lattice_dt(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_in_meters = (np.linalg.norm( dif.allBragg_coord_1[60] - dif.centerpos ) * 13e-6) \n",
    "two_theta_from_geom = np.arctan(distance_in_meters/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(dif.first_image.shape[0])\n",
    "y1 = np.arange(dif.first_image.shape[1])\n",
    "x1, y1 = np.meshgrid(x1, y1)\n",
    "\n",
    "sel_corners = (\n",
    "    (y1< ((100-0)/100)*x1 - 900) + (y1< ((-100)/100)*x1 +150) + \n",
    "    (y1> ((100-0)/100)*x1 + 900) + (y1> ((-100)/100)*x1 +900+900+140)\n",
    ")\n",
    "\n",
    "dif.first_image /= dif.first_image[sel_corners].mean()\n",
    "dif.last_image /= dif.last_image[sel_corners].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_corners = (\n",
    "#                 (y< ((100-0)/100)*x - 900) + (y< ((-100)/100)*x +150) + \n",
    "#                 (y> ((100-0)/100)*x + 900) + (y> ((-100)/100)*x +900+900+140)\n",
    "#             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise first and last image by i0 intensity ( for compatibilty )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to change and update this so that it matches the normalisation method I am now using: aka the donut ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise first and last image by i0 intensity ( for compatibilty )\n",
    "temp_fits = np.zeros((20,6))\n",
    "\n",
    "for i, i0_fname in enumerate(dif.fnames_I0[0:20]):\n",
    "#     print(i0_fname)\n",
    "    temp_fits[i] = ued_dt.load_and_fit_i0(i0_fname)\n",
    "\n",
    "# temp_fits0 = np.zeros(6)\n",
    "temp_fits0 = np.mean(temp_fits, axis = 0)\n",
    "\n",
    "# dif.first_image /= temp_fits0[0]*temp_fits0[3]*temp_fits0[4] #old for i0 normalisation\n",
    "# dif.first_image /= dif.first_image[dif.donut_mask].mean() #this is for donut normalisation\n",
    "dif.first_image /= dif.first_image[sel_corners].mean() #this is for corner normalisation\n",
    "\n",
    "# image /= image[sel_corners].mean()\n",
    "\n",
    "\n",
    "\n",
    "for i, i0_fname in enumerate(dif.fnames_I0[-20:]):\n",
    "#     print(i0_fname)\n",
    "    temp_fits[i] = ued_dt.load_and_fit_i0(i0_fname)\n",
    "\n",
    "# temp_fits0 = np.zeros(6)\n",
    "temp_fits0 = np.mean(temp_fits, axis = 0)\n",
    "\n",
    "# dif.last_image /= temp_fits0[0]*temp_fits0[3]*temp_fits0[4] #old for i0 normalisation\n",
    "# dif.last_image /=dif.last_image[dif.donut_mask].mean()\n",
    "dif.last_image /=dif.last_image[sel_corners].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### select two opposite ROIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.roisize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select ROIS that have their Pair\n",
    "dif.allBragg_coord_2, dif.allBragg_names_2, dif.allBragg_indices_2 = np.asarray(dif.allBragg_coord_1), np.asarray(dif.allBragg_names_1), np.asarray(dif.allBragg_indices_1)\n",
    "# dif.roisize = 20\n",
    "dif.roisize = 40\n",
    "\n",
    "dif.sel_bragg_in_im = (\n",
    "    (dif.allBragg_coord_2[:,0] > 0 + dif.roisize )&\n",
    "    (dif.allBragg_coord_2[:,0] < dif.first_image.shape[0] - dif.roisize )&\n",
    "    (dif.allBragg_coord_2[:,1] > 0 + dif.roisize )&\n",
    "    (dif.allBragg_coord_2[:,1] < dif.first_image.shape[1] - dif.roisize )    \n",
    ")\n",
    "\n",
    "dif.sel_bragg_in_im =(dif.sel_bragg_in_im*dif.sel_bragg_in_im[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# this loop takes 2s per scattering pattern \n",
    "#set xx and yy coordinate frame \n",
    "dif.x = np.arange(dif.first_image.shape[0])\n",
    "dif.y = np.arange(dif.first_image.shape[1])\n",
    "\n",
    "dif.xx, dif.yy = np.meshgrid(dif.x,dif.y)\n",
    "\n",
    "image = dif.first_image\n",
    "\n",
    "centers = np.zeros_like(dif.allBragg_coord_2)\n",
    "\n",
    "bragg_fits = np.zeros((120, 7))\n",
    "fit_erros = np.zeros((120, 7,7))\n",
    "\n",
    "\n",
    "\n",
    "for i in np.arange(len(dif.allBragg_names_1)//2):\n",
    "#     print(i)\n",
    "    if dif.sel_bragg_in_im[i]:\n",
    "#         print(f'yay nb: {i} and {np.arange(120)[::-1][i]}')\n",
    "\n",
    "        ### ROI 1: \n",
    "        roi_1_lower_left = (dif.allBragg_coord_2[i] - dif.roisize).astype(int)\n",
    "        roi_1_upper_right = (dif.allBragg_coord_2[i] + dif.roisize).astype(int)\n",
    "        roi_1_selx  = np.arange(roi_1_lower_left[1],roi_1_upper_right[1])\n",
    "        roi_1_sely =  np.arange(roi_1_lower_left[0],roi_1_upper_right[0])\n",
    "        roi_1 = image[roi_1_selx,:][:,roi_1_sely]\n",
    "\n",
    "        ### ROI 2: \n",
    "        roi_2_lower_left = (dif.allBragg_coord_2[::-1][i] - dif.roisize).astype(int)\n",
    "        roi_2_upper_right = (dif.allBragg_coord_2[::-1][i] + dif.roisize).astype(int)\n",
    "        roi_2_selx  = np.arange(roi_2_lower_left[1],roi_2_upper_right[1])\n",
    "        roi_2_sely =  np.arange(roi_2_lower_left[0],roi_2_upper_right[0])\n",
    "        roi_2 = image[roi_2_selx,:][:,roi_2_sely]\n",
    "\n",
    "\n",
    "        ### Fit ROIs with a 2D gaussian: \n",
    "#         def twoD_Gaussian(xx_yy, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "        vmin = np.percentile(roi_1, 2)\n",
    "        vmax = np.percentile(roi_1, 95)\n",
    "        initial_guess_1 = (vmax-vmin, dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],5,5,0,vmin)\n",
    "#         initial_guess_1 = (10,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],10,10,0,1)\n",
    "        xx_yy_1 = (dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely])\n",
    "        popt_1, pcov_1 = opt.curve_fit(ued_dt.Gaussian_2D1, xx_yy_1, roi_1.ravel(), p0=initial_guess_1)\n",
    "        \n",
    "        vmin = np.percentile(roi_2, 2)\n",
    "        vmax = np.percentile(roi_2, 95)\n",
    "        initial_guess_2 = (vmax-vmin,dif.allBragg_coord_2[::-1][i][0],dif.allBragg_coord_2[::-1][i][1],5,5,0,vmin)\n",
    "#         initial_guess_2 = (10,dif..allBragg_coord_2[::-1][i][0],dif..allBragg_coord_2[::-1][i][1],10,10,0,1)\n",
    "        xx_yy_2 = (dif.xx[roi_2_selx,:][:,roi_2_sely], dif.yy[roi_2_selx,:][:,roi_2_sely])\n",
    "        popt_2, pcov_2 = opt.curve_fit(ued_dt.Gaussian_2D1, xx_yy_2, roi_2.ravel(), p0=initial_guess_2)\n",
    "        \n",
    "        centers[i]  = popt_1[1], popt_1[2]\n",
    "        centers[::-1][i] = popt_2[1], popt_2[2]\n",
    "        \n",
    "        bragg_fits[i] =popt_1\n",
    "        bragg_fits[::-1][i] = popt_2\n",
    "        \n",
    "        fit_erros[i] = pcov_1\n",
    "        fit_erros[::-1][i] = pcov_2\n",
    "\n",
    "        \n",
    "    else:\n",
    "#         print(f'nay nb: {i} and {np.arange(120)[::-1][i]}')\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image, vmin = np.percentile(image, 5), vmax= np.percentile(image, 95) ) \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(image, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center of the scattering image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "avg_fit = (0.5*(bragg_fits[::-1, :] + bragg_fits[:,:]))[dif.sel_bragg_in_im][:-1]\n",
    "test_sel = np.where((avg_fit[:,2] != 0.)&(avg_fit[:,1] != 0.))\n",
    "\n",
    "\n",
    "cent_test = np.zeros((int(dif.max_frame/dif.frame_step),2))\n",
    "for i in np.arange(int(dif.max_frame/dif.frame_step)):\n",
    "    avg_fit = (0.5*(bragg_fits[::-1, :] + bragg_fits[:,:]))[dif.sel_bragg_in_im][:-1]\n",
    "    test_sel = np.where((avg_fit[:,2] != 0.)&(avg_fit[:,1] != 0.))\n",
    "    \n",
    "    cent_test[i] = avg_fit[test_sel, 1:3].mean(axis = 1)[0]\n",
    "\n",
    "\n",
    "\n",
    "# i=0\n",
    "avg_fit = (0.5*(bragg_fits[::-1, :] + bragg_fits[:,:]))[dif.sel_bragg_in_im][:-1]\n",
    "test_sel = np.where((avg_fit[:,2] != 0.)&(avg_fit[:,1] != 0.))\n",
    "\n",
    "plt.plot(avg_fit[test_sel,1], \n",
    "            avg_fit[test_sel,2], '.', color=f'C{i}');\n",
    "plt.scatter(cent_test[i][0],cent_test[i][1], color=f'r', s=75, zorder=100)\n",
    "plt.scatter(dif.centerpos[0], dif.centerpos[1], color='k',zorder=100, s=75)\n",
    "\n",
    "plt.xlabel('x pos (px)')\n",
    "plt.ylabel('y pos (px)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Static Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## azimuthal background Vs powder XRD-like plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.static.background = dif.Static() # Container for static bakcground data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = np.ones_like(dif.first_image)\n",
    "\n",
    "\n",
    "sx, sy = dif.first_image.shape\n",
    "xcoord, ycoord = np.ogrid[:sx, :sy]\n",
    "for i in range(len(dif.allBragg_coord_1)):\n",
    "    mask[np.hypot(xcoord - dif.allBragg_coord_1[i][1], ycoord- dif.allBragg_coord_1[i][0]) < 40 ] =np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_img = dif.first_image*mask\n",
    "\n",
    "# inv_mask = np.ones_like(mask)\n",
    "# inv_mask[np.invert(np.isnan(mask))] = np.nan\n",
    "\n",
    "masked_img = dif.first_image*mask\n",
    "inv_mask = np.ones_like(mask)\n",
    "inv_mask[np.invert(np.isnan(mask))] = np.nan\n",
    "\n",
    "masked_img_inv = dif.first_image*inv_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(ncols = 2, figsize = (12,5)) \n",
    "\n",
    "vmin = np.percentile(masked_img[~np.isnan(masked_img)],  1)\n",
    "vmax = np.percentile(masked_img[~np.isnan(masked_img)], 99)\n",
    "\n",
    "im1=ax1.pcolormesh(masked_img, vmin = vmin, vmax=vmax)\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "\n",
    "vmin = np.percentile((dif.first_image*inv_mask)[~np.isnan(dif.first_image*inv_mask)],  1)\n",
    "vmax = np.percentile((dif.first_image*inv_mask)[~np.isnan(dif.first_image*inv_mask)], 99)\n",
    "\n",
    "im2=ax2.pcolormesh(dif.first_image*(inv_mask), vmin = vmin, vmax=vmax)\n",
    "plt.colorbar(im2, ax=ax2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax0, ax1, ax2] = plt.subplots(ncols = 3, figsize = (18,5), dpi = 300) \n",
    "\n",
    "\n",
    "\n",
    "# vmin = np.percentile(masked_img[~np.isnan(masked_img)],  1)\n",
    "# vmax = np.percentile(masked_img[~np.isnan(masked_img)], 99)\n",
    "vmin = np.percentile(dif.first_image[~np.isnan(dif.first_image)],  1)\n",
    "vmax = np.percentile(dif.first_image[~np.isnan(dif.first_image)], 99)\n",
    "\n",
    "im0=ax0.pcolormesh(dif.first_image, vmin = vmin, vmax=vmax)\n",
    "\n",
    "im1=ax1.pcolormesh(masked_img, vmin = vmin, vmax=vmax)\n",
    "# plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "\n",
    "vmin = np.percentile((dif.first_image*inv_mask)[~np.isnan(dif.first_image*inv_mask)],  1)\n",
    "vmax = np.percentile((dif.first_image*inv_mask)[~np.isnan(dif.first_image*inv_mask)], 99)\n",
    "\n",
    "im2=ax2.pcolormesh(masked_img_inv, vmin = vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azimuthal Integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_vals, azimuthal_vals, norm_test= dif.azimuthal_average_DT(image = masked_img, norm_out=True)\n",
    "dif.dist_vals_bkg, dif.azimuthal_vals_bkg, dif.norm_test_bkg = dif.azimuthal_average_DT(image = masked_img, norm_out=True) #dist_vals, azimuthal_vals, norm_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_vals, azimuthal_vals, norm_test= dif.azimuthal_average_DT(image = dif.first_image, norm_out=True)\n",
    "dif.dist_vals_bkg, dif.azimuthal_vals_bkg, dif.norm_test_bkg = dif.azimuthal_average_DT(image = masked_img, norm_out=True) #dist_vals, azimuthal_vals, norm_test\n",
    "dif.dist_vals_peaks, dif.azimuthal_vals_peaks, dif.norm_test_peaks = dif.azimuthal_average_DT(image = masked_img_inv, norm_out=True) #dist_vals, azimuthal_vals, norm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( dif.dist_vals_bkg, dif.azimuthal_vals_bkg, label = 'azimuthal value')\n",
    "# plt.plot( dist_vals, norm_test/10000000)\n",
    "plt.plot( dif.dist_vals_bkg, dif.norm_test_bkg/1000, label='number of pixels at particular  q')\n",
    "\n",
    "plt.ylabel('intensity (arb. units)')\n",
    "plt.xlabel('Q (px)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_dependence (image, center = None, min_dist = 0, max_dist = None, dr= 1,  min_theta=0, max_theta = 360, dtheta = 1, norm_out=False ):\n",
    "    '''\n",
    "    calculates the azimuthal average intensity of image taking a custom center of the image \n",
    "    takes: \n",
    "    image: the image to consider\n",
    "    center: the center, has to be in px and in the image coordinates\n",
    "    min dist: minimum distance to consider\n",
    "    max_dist = maximum distance to consider: useful when calculating sub peaks \n",
    "    dr: how many pixels should each ring be in doubt: leave it alone\n",
    "\n",
    "    returns: \n",
    "    azimuthal_vals: average intensities: it's an \"intensity\" per pixel area\n",
    "    dist_vals : distances in pixels calculated \n",
    "    norm: number of pixels considered at each distance, useful for debugging\n",
    "\n",
    "    Author: Diego Turenne\n",
    "    '''\n",
    "    if not np.shape(center): center = dif.centerpos\n",
    "    if not np.shape(image): image = dif.first_image\n",
    "\n",
    "    if max_dist == None: \n",
    "#            max_dist = np.max(image.shape)*np.sqrt(2)/2\n",
    "        max_dist = np.max(image.shape)*np.sqrt(2)\n",
    "        print(max_dist)\n",
    "\n",
    "    # calculate distance to the center: \n",
    "    x_index = np.arange(image.shape[0])\n",
    "    y_index = np.arange(image.shape[1])\n",
    "\n",
    "    # reshape array so that they have get broadcasted the right way:\n",
    "    x_index =  np.expand_dims(x_index, 1)\n",
    "    y_index =  np.expand_dims(y_index, 0)\n",
    "\n",
    "    #create array of with disntaces\n",
    "    distance_array = np.sqrt((x_index-center[1])**2 + (y_index - center[0])**2)  # weird python coord system\n",
    "    angular_array = np.arctan2(x_index-center[1], y_index - center[0]) \n",
    "    angular_array = np.rad2deg(angular_array) + 180\n",
    "#     print('angle ranges')\n",
    "#     print(angular_array.min())\n",
    "#     print(angular_array.max())\n",
    "    # create vectors to put the data in \n",
    "    dist_vals = np.arange(min_dist, max_dist, dr)\n",
    "    angles = np.arange(min_theta, max_theta, dtheta) \n",
    "#     print('angle ranges on the loop')\n",
    "#     print(angles)\n",
    "\n",
    "#     print(dist_vals)\n",
    "    azimuthal_vals = np.zeros_like(dist_vals)\n",
    "    angular_vals = np.zeros(angles.shape)\n",
    "#     norm = np.zeros_like(dist_vals)\n",
    "    norm = np.zeros_like(angles)\n",
    "\n",
    "    # loop over theistance ,mask everything that's not in the ROI and calc mean \n",
    "    for i, theta in enumerate(angles):\n",
    "#         print(theta)\n",
    "        mask = (angular_array >= theta) & (angular_array < theta + dtheta) & (distance_array < max_dist ) & (distance_array > min_dist )\n",
    "        norm[i] = np.nansum(mask)\n",
    "        try:\n",
    "            angular_vals[i] = np.nanmean(image[mask])\n",
    "#             print('passed through the non error')\n",
    "        except:\n",
    "#             print('cunt')\n",
    "            angular_vals[i] = False\n",
    "#         sel = not np.isnan(azimuthal_vals)\n",
    "#         azimuthal_vals = azimuthal_vals[sel]\n",
    "#         dist_vals = dist_vals[sel]\n",
    "#     return angular_array, mask, angles, angular_vals, norm\n",
    "    \n",
    "    if norm_out:\n",
    "        return mask, angles, angular_vals, norm\n",
    "    else:\n",
    "        return mask, angles, angular_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pcolormesh(masked_img -np.nanmean(masked_img), cmap = 'seismic', vmin = -4, vmax=4)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_mask,  angles, angular_values = angular_dependence(masked_img, center =None,\n",
    "# angle_mask,  angles, angular_values = angular_dependence(dif.first_image*(inv_mask), center =None,\n",
    "                                                         min_dist = 125, max_dist = 450, \n",
    "#                                                          min_dist = 175, max_dist = 450,  # 4 fold symmetry \n",
    "#                                                          min_dist = 40, max_dist =100,   # low q high diffuse intensity\n",
    "#                                                          min_dist = 100, max_dist = 250, # the other 4 fold symmetry at 45 degrees \n",
    "                                                         min_theta=0, max_theta = 360, dtheta =1, norm_out=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(angles, angular_values/angular_values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(np.deg2rad(angles-180), angular_values, '.-' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10,10))\n",
    "# # plt.imshow(angular_array*mask_angle, cmap = 'seismic')\n",
    "# vmin = np.percentile(masked_img[~np.isnan(masked_img)],  1)\n",
    "# vmax = np.percentile(masked_img[~np.isnan(masked_img)], 99)\n",
    "# plt.imshow(masked_img, vmin = vmin, vmax=vmax)\n",
    "# # plt.imshow(dif.first_image*(inv_mask), vmin= 0, vmax= 1, cmap='binary' )\n",
    "# # plt.imshow(dif.first_image*(inv_mask), vmin= 0, vmax= 1, cmap='binary' )\n",
    "\n",
    "# plt.imshow(dif.first_image*angle_mask, vmax= .1, alpha = 0.2 )#cmap = 'seismic')\n",
    "# plt.scatter(dif.bragg_fits_binned_delays[0,:,1], dif.bragg_fits_binned_delays[0,:,2])\n",
    "\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FePt_a = 2.72814\n",
    "FePt_a_YK = 3.85/np.sqrt(2)\n",
    "FePt_a = FePt_a_YK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FePt_a = 2.735 # I just want to try out this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FePt_a_YK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2*np.pi/FePt_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_vals_pks, azimuthal_vals_pks, norm = dif.azimuthal_average_DT(image = dif.first_image*(inv_mask), norm_out = True)\n",
    "dif.dist_vals_pks, dif.azimuthal_vals_pks, dif.norm_pks  = dif.azimuthal_average_DT(image = dif.first_image*(inv_mask), norm_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.where(dif.azimuthal_vals_pks == np.nanmax(dif.azimuthal_vals_pks[np.where(dif.dist_vals_pks < 150)]) )[0][0]\n",
    "max_idx = np.where(dif.azimuthal_vals_pks == np.nanmax(dif.azimuthal_vals_pks[np.where(dif.dist_vals_pks < 120)]) )[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_old = (2*np.pi/FePt_a) / dif.dist_vals_pks[max_idx]\n",
    "coef0 = 0.02253073560552693 #(by fitting sloped gaussians to Bi 110)\n",
    "# print(coef)\n",
    "\n",
    "# coef0 is: 0.022575998277514275\n",
    "# coef0 is: 0.02253073560552693 #(by fitting sloped gaussians to Bi 110)\n",
    "\n",
    "\n",
    "\n",
    "coef1 = np.load('../coef1_8_august_2023.npy')\n",
    "\n",
    "\n",
    "coef = copy.copy(coef1)\n",
    "print(coef_old)\n",
    "print(coef0)\n",
    "print(coef1)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.02257496241448873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using the calibration of pixels used on Bismuth\n",
    "# coef_Bi = 8.29849/350 # ~0.023709971428571428   ;  8.29849: value of the 330 Bi diffraction peak in A-1, 350: px value obtained on the detector\n",
    "# print(coef_Bi)\n",
    "# coef = coef_Bi # overrifing the previous calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.coef = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.plot( coef*dif.dist_vals_pks, dif.azimuthal_vals_pks, c='C3')\n",
    "plt.xlabel('Q ($ \\AA^{-1}$)')\n",
    "\n",
    "plt.axvline(np.sqrt( (4*2*np.pi/(FePt_a))**2 + ( 1*2*np.pi/(FePt_a))**2 ) , c= 'k', ls='--') #320\n",
    "\n",
    "plt.xlim(7,14)\n",
    "plt.ylim(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate lattice from measured lattice constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_atoms = 20\n",
    "\n",
    "FePt_a = 2.72814\n",
    "FePt_b = 2.72814\n",
    "FePt_c = 3.77898\n",
    "\n",
    "lattice_constant = 2*np.pi/2.72814 # this uses the tabulated value. \n",
    "lattice_constant = (coef*dif.dist_vals_pks[ np.where(dif.azimuthal_vals_pks == np.nanmax(dif.azimuthal_vals_pks))]/np.sqrt(2))[0] # this uses the measured value, assuming the calibration was done properly\n",
    "# print(lattice_constant)\n",
    "row = np.arange(-nb_atoms*lattice_constant/2,+nb_atoms*lattice_constant/2,lattice_constant)\n",
    "row_idx = np.arange( -nb_atoms//2, nb_atoms//2)\n",
    "\n",
    "\n",
    "dif.bragg_pos = []\n",
    "dif.hk_idx = []\n",
    "idx = 0\n",
    "for i_idx, i in enumerate(row):\n",
    "    for j_idx, j in enumerate(row):\n",
    "        dif.bragg_pos.append( [i, j] )\n",
    "        dif.hk_idx.append([row_idx[i_idx], row_idx[j_idx]])\n",
    "        idx += 1\n",
    "dif.bragg_pos = np.asarray(dif.bragg_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: X-ray form factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: plot XRD pattern for X-rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_XRD = np.zeros_like(dif.bragg_pos[:,0])\n",
    "\n",
    "for i in range(len(F_XRD)):\n",
    "    q_tmp = np.sqrt((dif.bragg_pos[i]**2).sum())\n",
    "    f_Fe = dt.form_factor(q_tmp, element = 'Fe')\n",
    "    f_Pt = dt.form_factor(q_tmp, element = 'Pt')\n",
    "    f_C = dt.form_factor(q_tmp, element = 'C')\n",
    "    \n",
    "    if np.asarray(dif.hk_idx)[i].sum() % 2 : #if odd\n",
    "        F_XRD[i] = f_Pt - f_Fe\n",
    "    else:\n",
    "        F_XRD[i] = f_Pt + f_Fe\n",
    "dif.I_XRD = F_XRD**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(dif.hk_idx, columns=['h', 'k'] )\n",
    "zero_order_idx = df2[(df2['h'] == 0)&(df2['k'] == 0)].index[0]\n",
    "dif.I_XRD[zero_order_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor = \"white\", figsize = (8,8) )\n",
    "plt.scatter(dif.bragg_pos[:,0],dif.bragg_pos[:,1],s = 500*dif.I_XRD/np.max(dif.I_XRD) )\n",
    "\n",
    "plt.xlim(-10.,10.)\n",
    "plt.ylim(-10.,10.)\n",
    "\n",
    "plt.xlabel(r'$ \\AA^{-1} $')\n",
    "plt.ylabel(r'$ \\AA^{-1} $')\n",
    "plt.title('Reciprocal lattice ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Use X-ray From factors to calculate electron from factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "F_UED = np.zeros_like(dif.bragg_pos[:,0])\n",
    "\n",
    "for i in range(len(F_UED)):\n",
    "    q_tmp = np.sqrt((dif.bragg_pos[i]**2).sum())\n",
    "    f_Fe = dt.electron_form_factor(q_tmp, element = 'Fe')\n",
    "    f_Pt = dt.electron_form_factor(q_tmp, element = 'Pt')\n",
    "    f_C = dt.electron_form_factor(q_tmp, element = 'C')\n",
    "    \n",
    "    if np.asarray(dif.hk_idx)[i].sum() % 2 : #if odd\n",
    "        F_UED[i] = f_Pt - f_Fe\n",
    "    else:\n",
    "        F_UED[i] = f_Pt + f_Fe\n",
    "dif.I_UED = F_UED**2\n",
    "\n",
    "\n",
    "dif.I_UED[zero_order_idx] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor = \"white\", figsize = (8,8) )\n",
    "plt.scatter(dif.bragg_pos[:,0],dif.bragg_pos[:,1],s = 500*dif.I_UED/np.max(dif.I_UED) )\n",
    "# plt.axvline(0, c='k', ls ='--')\n",
    "# plt.plot( a-a.max(), b, '-', c='C1' )\n",
    "\n",
    "plt.xlim(-10.,10.)\n",
    "plt.ylim(-10.,10.)\n",
    "plt.xlabel(r'$ \\AA^{-1} $')\n",
    "plt.ylabel(r'$ \\AA^{-1} $')\n",
    "# plt.xlim(-2.,2.)\n",
    "# plt.ylim(-2.,2.)\n",
    "plt.title('Reciprocal lattice ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot electron diffraction pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = -5.340708\n",
    "theta = 0\n",
    "\n",
    "pos_x2 = np.cos(theta) * dif.bragg_pos[:,0] - np.sin(theta) *dif.bragg_pos[:,1]\n",
    "pos_y2 = np.sin(theta) * dif.bragg_pos[:,0] + np.cos(theta) *dif.bragg_pos[:,1]\n",
    "\n",
    "fig = plt.figure(\n",
    "    facecolor = \"white\",\n",
    "           figsize = (0.98*8,0.98*8) )\n",
    "# plt.scatter(dif.bragg_pos[:,0],dif.bragg_pos[:,1],s = 500*I_UED/np.max(I_UED) )\n",
    "plt.scatter(pos_x2,pos_y2,s = 500*dif.I_UED/np.max(dif.I_UED) )\n",
    "\n",
    "\n",
    "# plt.axvline(0, c='k', ls ='--')\n",
    "# plt.plot( a-a.max(), b, '-', c='C1' )\n",
    "\n",
    "plt.xlim(-10.,10.)\n",
    "plt.ylim(-10.,10.)\n",
    "plt.xlabel(r'$ \\AA^{-1} $')\n",
    "plt.ylabel(r'$ \\AA^{-1} $')\n",
    "# plt.xlim(-2.,2.)\n",
    "# plt.ylim(-2.,2.)\n",
    "plt.title('Reciprocal lattice ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Center position to show the Static UED pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(dif.first_image.shape[0])\n",
    "# (x- dif.centerpos[0])*coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.centerpos\n",
    "dif.x_inv_angstrom = np.arange(dif.first_image.shape[0])\n",
    "dif.x_inv_angstrom =( dif.x_inv_angstrom- dif.centerpos[0])*dif.coef\n",
    "\n",
    "dif.y_inv_angstrom = np.arange(dif.first_image.shape[1])\n",
    "dif.y_inv_angstrom =( dif.y_inv_angstrom- dif.centerpos[1])*dif.coef\n",
    "\n",
    "dif.xx_inv_angstrom, dif.yy_inv_angstrom = np.meshgrid(dif.x_inv_angstrom, dif.y_inv_angstrom)\n",
    "\n",
    "# coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,6))\n",
    "plt.pcolormesh(dif.xx_inv_angstrom, dif.yy_inv_angstrom, dif.first_image, vmin= vmin, vmax=vmax*2)\n",
    "plt.xlabel(r'$\\AA^{-1}$')\n",
    "plt.ylabel(r'$\\AA^{-1}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,6))\n",
    "plt.pcolormesh(dif.xx_inv_angstrom, dif.yy_inv_angstrom, dif.first_image, vmin= vmin, vmax=vmax*2)\n",
    "plt.xlabel(r'$\\AA^{-1}$')\n",
    "plt.ylabel(r'$\\AA^{-1}$')\n",
    "\n",
    "plt.xlim(-8,8)\n",
    "plt.ylim(-8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Atomic electron scattering coefs to simulate atomic scattering from Pt alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_str = 'Pt'\n",
    "def I_atom_f(Q, base, alpha):\n",
    "    '''\n",
    "    I am too lazy to write somthing proper now\n",
    "    '''\n",
    "    return base + alpha*dt.electron_form_factor(Q, element = element_str)**2\n",
    "\n",
    "\n",
    "\n",
    "def I_atom_alt_f(Q, base, alpha):\n",
    "    '''\n",
    "    fits x^-1.5 function \n",
    "    '''\n",
    "#     return base+ alpha/Q**1.5\n",
    "    return base+ alpha/Q**1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sel_tmp = np.where((dif.coef*dif.dist_vals_bkg < 11)&(dif.coef*dif.dist_vals_bkg > 7))\n",
    "# sel_tmp = np.where((coef*dist_vals < 11)&(coef*dist_vals > 1))\n",
    "# sel_tmp = np.where((coef*dist_vals < 10)&(coef*dist_vals > 6))\n",
    "# sel_tmp = np.where((coef*dist_vals < 10)&(coef*dist_vals > 1))\n",
    "\n",
    "popt , pcov = sp.optimize.curve_fit(I_atom_f, dif.coef*dif.dist_vals_bkg[sel_tmp],\n",
    "                                        dif.azimuthal_vals_bkg[sel_tmp], p0 = [300, 200])\n",
    "\n",
    "\n",
    "\n",
    "# popt , pcov = sp.optimize.curve_fit(I_atom_alt_f, coef*dist_vals[sel_tmp],\n",
    "#                                         azimuthal_vals[sel_tmp], p0 = [300, 200])\n",
    "# err_avg = np.sqrt(np.diag(pcov))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Check the homogenous background to atomic scattering of different species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(\n",
    "     facecolor = \"white\",\n",
    "    figsize = (8,8)\n",
    ")\n",
    "\n",
    "base = popt[0]\n",
    "alpha = popt[1]\n",
    "plt.plot(coef*dif.dist_vals_bkg, dif.azimuthal_vals_bkg, label = 'Experimental intensity')\n",
    "\n",
    "plt.plot(dif.coef*dif.dist_vals_bkg[20:], I_atom_f(coef*dif.dist_vals_bkg[20:], base, alpha),\n",
    "# plt.plot(Q, I_atom_alt_f(Q, base, alpha),\n",
    "\n",
    "         color = 'k', \n",
    "         label = element_str + f': a|f|$^2$ + b, a= {int(alpha)}, b= {int(base)}')\n",
    "\n",
    "\n",
    "# plt.plot(Q, 30*electron_form_factor(Q, element = 'Fe'))\n",
    "plt.legend(frameon = False, fontsize = 16)\n",
    "# plt.xlim(0,14)\n",
    "# plt.ylim(400,900)\n",
    "\n",
    "# fig.savefig('Carbon_e_form_factor.png', transparent = True)\n",
    "# fig.savefig('C_e_form_factor.png', transparent = True)\n",
    "\n",
    "# plt.figure(facecolor = \"white\",\n",
    "#     figsize = (8,8))\n",
    "\n",
    "# plt.plot(coef*dist_vals, norm)\n",
    "\n",
    "plt.xlim(0,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcoord.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Background images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_array = np.hypot(xcoord -  dif.centerpos[1], ycoord- dif.centerpos[0])\n",
    "\n",
    "angular_array = np.arctan2(xcoord-dif.centerpos[1], ycoord - dif.centerpos[0]) \n",
    "angular_array = np.rad2deg(angular_array) + 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_full_ring  = interpolate.interp1d(dif.coef*dif.dist_vals_bkg, dif.azimuthal_vals_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.bkg_img_fit = np.zeros_like(dist_array)\n",
    "dif.bkg_img_bkg = np.zeros_like(dist_array)\n",
    "dif.bkg_img_bkg_angular = np.zeros_like(dist_array)\n",
    "dr=1\n",
    "maxdist = int(np.max(dif.dist_vals_bkg))\n",
    "for i, dist  in enumerate(range(dr, maxdist, dr)):\n",
    "#     print(i)\n",
    "#     print(dist)\n",
    "    ring_mask = (dist_array >= (dist - dr)) * (dist_array <= dist)\n",
    "    dif.bkg_img_fit[ring_mask] = I_atom_f(dist*dif.coef, base, alpha)\n",
    "    dif.bkg_img_bkg[ring_mask] = f_full_ring(dist*dif.coef)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtheta = angles[1] - angles[0]\n",
    "dif.bkg_img_bkg_angular = copy.copy(dif.bkg_img_bkg)\n",
    "for i, theta in enumerate(angles):\n",
    "    mask = (angular_array >= theta) & (angular_array < theta + dtheta)\n",
    "\n",
    "    dif.bkg_img_bkg_angular[mask] *= angular_values[i]/angular_values.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_values[i]/angular_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, angle in enumerate(angles):\n",
    "#     angle_mask = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.percentile(dif.bkg_img_fit, 1)\n",
    "vmax = np.percentile(dif.bkg_img_fit, 99)\n",
    "\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(ncols =3, figsize = (12+6,6))\n",
    "im0 = ax1.imshow(dif.bkg_img_fit, vmin = vmin, vmax = vmax)\n",
    "ax1.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "ax1.set_title('dif.bkg_img_fit')\n",
    "plt.colorbar(im0, ax=ax1)\n",
    "\n",
    "im1 = ax2.imshow(dif.bkg_img_bkg, vmin = vmin, vmax = vmax)\n",
    "ax2.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "ax2.set_title('dif.bkg_img_bkg')\n",
    "plt.colorbar(im1, ax=ax2)\n",
    "\n",
    "im2 = ax3.imshow(dif.bkg_img_bkg_angular, vmin = vmin, vmax = vmax)\n",
    "ax3.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "ax3.set_title('dif.bkg_img_bkg_angular')\n",
    "plt.colorbar(im2, ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin-vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2, ax3, ax4] = plt.subplots(ncols =4, figsize = (26+8.6,6))\n",
    "\n",
    "vmin = np.percentile(dif.first_image - 0, 1)\n",
    "vmax = np.percentile(dif.first_image - 0, 98)\n",
    "im1 = ax1.pcolormesh(dif.first_image , vmin = vmin, vmax = vmax)\n",
    "ax1.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "\n",
    "\n",
    "# vmin = np.nanmin(dif.first_image - dif.bkg_img_fit)#np.percentile(dif.first_image - dif.bkg_img_fit, 0)\n",
    "# vmax = np.nanmax(dif.first_image - dif.bkg_img_fit)#np.percentile(dif.first_image - dif.bkg_img_fit, 100)\n",
    "# im2 = ax2.pcolormesh(dif.first_image - dif.bkg_img_fit ,norm=matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "# #                      vmin = vmin, vmax = vmax\n",
    "#                     )\n",
    "# ax2.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "# plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "\n",
    "\n",
    "vmin = np.nanmin(dif.first_image - dif.bkg_img_bkg) #np.percentile((dif.first_image - dif.bkg_img_bkg)[~np.isnan(dif.first_image - dif.bkg_img_bkg)], 1)\n",
    "vmax = np.nanmax(dif.first_image - dif.bkg_img_bkg) #np.percentile((dif.first_image - dif.bkg_img_bkg)[~np.isnan(dif.first_image - dif.bkg_img_bkg)], 95)\n",
    "\n",
    "im3 = ax3.pcolormesh(dif.first_image - dif.bkg_img_bkg-vmin+1 , \n",
    "                      norm=matplotlib.colors.LogNorm(vmin=vmin-vmin+1, vmax=vmax-vmin+1))\n",
    "#                      vmin = vmin, vmax = vmax)\n",
    "ax3.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "plt.colorbar(im3, ax=ax3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vmin = np.nanmin(dif.first_image - dif.bkg_img_bkg) #np.percentile((dif.first_image - dif.bkg_img_bkg)[~np.isnan(dif.first_image - dif.bkg_img_bkg)], 1)\n",
    "vmax = np.nanmax(dif.first_image - dif.bkg_img_bkg) #np.percentile((dif.first_image - dif.bkg_img_bkg)[~np.isnan(dif.first_image - dif.bkg_img_bkg)], 95)\n",
    "\n",
    "im4 = ax4.pcolormesh(dif.first_image - dif.bkg_img_bkg-vmin+1 , \n",
    "                      norm=matplotlib.colors.LogNorm(vmin=vmin-vmin+1, vmax=(vmax-vmin+1)/40))\n",
    "#                      vmin = vmin, vmax = vmax)\n",
    "ax4.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "plt.colorbar(im4, ax=ax4)\n",
    "\n",
    "\n",
    "\n",
    "# im4 = ax4.pcolormesh((dif.first_image - dif.bkg_img_bkg_angular)+vmin , \n",
    "#                      norm=matplotlib.colors.LogNorm(vmin=vmin+vmin, vmax=vmax+vmin))\n",
    "# #                      vmin = vmin, vmax = vmax)\n",
    "# ax4.plot(dif.centerpos[0],dif.centerpos[1],'.', c='r' )\n",
    "# plt.colorbar(im4, ax=ax4)\n",
    "\n",
    "\n",
    "ax1.set_title('raw image')\n",
    "\n",
    "ax2.set_title('raw image - Pt fit \\n (bkg_img_fit)')\n",
    "ax3.set_title('raw image - azimuthal integration \\n (bkg_img_bkg)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use backgrounds to analyse static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.dist_vals_wo_bkg_fit, dif.azimuthal_vals_wo_bkg_fit = dif.azimuthal_average_DT(image = (dif.first_image - dif.bkg_img_fit)*mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sqrt_azimuthal_vals_bkg = np.sqrt(dif.azimuthal_vals_wo_bkg_fit)\n",
    "sqrt_azimuthal_vals_bkg[np.isnan(np.sqrt(dif.azimuthal_vals_wo_bkg_fit))] = 0 \n",
    "\n",
    "# Create function to get any value of Q \n",
    "\n",
    "# azimuthal_vals_bkg2 = azimuthal_vals_bkg\n",
    "# azimuthal_vals_bkg[azimuthal_vals_bkg <= 0] = 0\n",
    "# azimuthal_vals_bkg_intrp = interpolate.interp1d(coef*dist_vals_bkg, azimuthal_vals_bkg2 ) \n",
    "dif.static.background.azimuthal_vals_bkg_intrp = interpolate.interp1d(dif.coef*dif.dist_vals_wo_bkg_fit, dif.azimuthal_vals_wo_bkg_fit ) \n",
    "dif.static.background.sqrt_azimuthal_vals_bkg_intrp = interpolate.interp1d(dif.coef*dif.dist_vals_wo_bkg_fit, dif.azimuthal_vals_wo_bkg_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(dif.coef*dif.dist_vals_wo_bkg_fit, dif.azimuthal_vals_wo_bkg_fit)\n",
    "\n",
    "# plt.axvline(2*np.pi/FePt_c, ls='--', c='k')\n",
    "# plt.axvline(np.sqrt((2*np.pi/FePt_a)**2 + (2*np.pi/FePt_c)**2), ls='--', c='k')\n",
    "# plt.axvline(2*np.pi/FePt_a, ls='--', c='k')\n",
    "\n",
    "plt.xlim(0,16)\n",
    "# plt.axvline(2*np.pi/FePt_a)\n",
    "plt.ylim(-.1,.4)\n",
    "plt.axhline(0, c='k', ls= '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx1 = dif.dist_vals_wo_bkg_fit[45:700]#+dif.centerpos[0]\n",
    "testy1 = 1000*dif.azimuthal_vals_wo_bkg_fit[45:700] #+ dif.centerpos[1]\n",
    "\n",
    "theta = np.pi/4\n",
    "test_x2 = np.cos(theta) * testx1 - np.sin(theta) *testy1\n",
    "test_y2 = np.sin(theta) * testx1 + np.cos(theta) *testy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mask*(dif.first_image - dif.bkg_img_fit), vmin = -2, vmax = 2, origin = 'lower')\n",
    "# plt.plot(dist_vals_bkg[45:700]+dif.centerpos[0], azimuthal_vals_bkg[45:700] + dif.centerpos[1])\n",
    "plt.plot(test_x2+dif.centerpos[0], test_y2+ dif.centerpos[1], color = 'red')\n",
    "plt.colorbar()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use empty image to subtract it from images and then re-fit Bragg peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(dif.first_image.shape[0])\n",
    "# y = np.arange(dif.first_image.shape[1])\n",
    "\n",
    "# xx, yy = np.meshgrid(x,y)\n",
    "\n",
    "\n",
    "# # sel_corners = (\n",
    "# #     (y< ((100-0)/100)*x - 900) + (y< ((-100)/100)*x +150) + \n",
    "# #     (y> ((100-0)/100)*x + 900) + (y> ((-100)/100)*x +900+900+140)\n",
    "# # )\n",
    "\n",
    "\n",
    "# image = dif.first_image\n",
    "\n",
    "# centers2 = np.zeros_like(dif.allBragg_coord_2)\n",
    "\n",
    "# dif.static.bragg_fits2 = np.zeros((10, 120, 7))\n",
    "# dif.static.fit_erros2 = np.zeros((10, 120, 7,7))\n",
    "\n",
    "\n",
    "# for idx, j in enumerate(np.arange(0,dif.max_frame,dif.frame_step)):\n",
    "#     print(idx, j)\n",
    "#     image = dif.load_img(dif.fnames[sel_pre_t0[0][j:j+(frame_step-1)]])\n",
    "# #     image = ued_dt.despike(image)\n",
    "# #     image /= image[sel_corners].mean()\n",
    "#     image /= image[dif.donut_mask].mean()\n",
    "    \n",
    "#     for i in np.arange(len(dif.allBragg_names_1)//2):\n",
    "#     #     print(i)\n",
    "#         if dif.sel_bragg_in_im[i]:\n",
    "            \n",
    "#             ### ROI 1: \n",
    "#             roi_1_lower_left = (dif.allBragg_coord_2[i] - dif.roisize).astype(int)\n",
    "#             roi_1_upper_right = (dif.allBragg_coord_2[i] + dif.roisize).astype(int)\n",
    "#             roi_1_selx  = np.arange(roi_1_lower_left[1],roi_1_upper_right[1])\n",
    "#             roi_1_sely =  np.arange(roi_1_lower_left[0],roi_1_upper_right[0])\n",
    "#             roi_1 = image[roi_1_selx,:][:,roi_1_sely]  - dif.bkg_img_fit[roi_1_selx,:][:,roi_1_sely]\n",
    "#             vmin1 = np.percentile(roi_1, 5)\n",
    "#             vmax1 = np.percentile(roi_1, 95)\n",
    "\n",
    "#             ### ROI 2: \n",
    "#             roi_2_lower_left = (dif.allBragg_coord_2[::-1][i] - dif.roisize).astype(int)\n",
    "#             roi_2_upper_right = (dif.allBragg_coord_2[::-1][i] + dif.roisize).astype(int)\n",
    "#             roi_2_selx  = np.arange(roi_2_lower_left[1],roi_2_upper_right[1])\n",
    "#             roi_2_sely =  np.arange(roi_2_lower_left[0],roi_2_upper_right[0])\n",
    "#             roi_2 = image[roi_2_selx,:][:,roi_2_sely]  - dif.bkg_img_fit[roi_2_selx,:][:,roi_2_sely]\n",
    "#             vmin2 = np.percentile(roi_2, 5)\n",
    "#             vmax2 = np.percentile(roi_2, 95)\n",
    "\n",
    "#             ### Fit ROIs with a 2D gaussian: \n",
    "#         #     def twoD_Gaussian(xx_yy, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "#             initial_guess_1 = (1,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],7.5,7.5,0,vmin1)\n",
    "#             xx_yy_1 = (xx[roi_1_selx,:][:,roi_1_sely], yy[roi_1_selx,:][:,roi_1_sely])\n",
    "#             popt_1, pcov_1 = opt.curve_fit(ued_dt.Gaussian_2D1, xx_yy_1, roi_1.ravel(), p0=initial_guess_1)\n",
    "\n",
    "#             initial_guess_2 = (1,dif.allBragg_coord_2[::-1][i][0],dif.allBragg_coord_2[::-1][i][1],7.5,7.5,0,vmin2)\n",
    "#             xx_yy_2 = (xx[roi_2_selx,:][:,roi_2_sely], yy[roi_2_selx,:][:,roi_2_sely])\n",
    "#             popt_2, pcov_2 = opt.curve_fit(ued_dt.Gaussian_2D1, xx_yy_2, roi_2.ravel(), p0=initial_guess_2)\n",
    "\n",
    "#             centers2[i]  = popt_1[1], popt_1[2]\n",
    "#             centers2[::-1][i] = popt_2[1], popt_2[2]\n",
    "            \n",
    "# #             print(popt_1)\n",
    "\n",
    "#             dif.static.bragg_fits2[idx][i] =popt_1\n",
    "#             dif.static.bragg_fits2[idx][::-1][i] = popt_2\n",
    "# #             print(bragg_fits[idx][i])\n",
    "            \n",
    "#             dif.static.fit_erros2[idx][i] = pcov_1\n",
    "#             dif.static.fit_erros2[idx][::-1][i] = pcov_2\n",
    "\n",
    "\n",
    "#         else:\n",
    "#     #         print(f'nay nb: {i} and {np.arange(120)[::-1][i]}')\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp.reload(ued_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(dif.first_image.shape[0])\n",
    "# y = np.arange(dif.first_image.shape[1])\n",
    "\n",
    "# xx, yy = np.meshgrid(x,y)\n",
    "\n",
    "\n",
    "# sel_corners = (\n",
    "#     (y< ((100-0)/100)*x - 900) + (y< ((-100)/100)*x +150) + \n",
    "#     (y> ((100-0)/100)*x + 900) + (y> ((-100)/100)*x +900+900+140)\n",
    "# )\n",
    "\n",
    "\n",
    "image = dif.first_image\n",
    "\n",
    "centers2 = np.zeros_like(dif.allBragg_coord_2)\n",
    "\n",
    "dif.static.bragg_fits2 = np.zeros((10, 120, 9))\n",
    "dif.static.fit_erros2 = np.zeros((10, 120, 9,9))\n",
    "\n",
    "\n",
    "for idx, j in enumerate(np.arange(0,dif.max_frame,dif.frame_step)):\n",
    "    print(idx, j)\n",
    "    image = dif.load_img(dif.fnames[sel_pre_t0[0][j:j+(dif.frame_step-1)]])\n",
    "#     image = ued_dt.despike(image)\n",
    "    image /= image[sel_corners].mean()\n",
    "#     image /= image[dif.donut_mask].mean()\n",
    "    \n",
    "    for i in np.arange(len(dif.allBragg_names_1)//2):\n",
    "    #     print(i)\n",
    "        if dif.sel_bragg_in_im[i]:\n",
    "            \n",
    "            ### ROI 1: \n",
    "            roi_1_lower_left = (dif.allBragg_coord_2[i] - dif.roisize).astype(int)\n",
    "            roi_1_upper_right = (dif.allBragg_coord_2[i] + dif.roisize).astype(int)\n",
    "            roi_1_selx  = np.arange(roi_1_lower_left[1],roi_1_upper_right[1])\n",
    "            roi_1_sely =  np.arange(roi_1_lower_left[0],roi_1_upper_right[0])\n",
    "            roi_1 = image[roi_1_selx,:][:,roi_1_sely]  - dif.bkg_img_fit[roi_1_selx,:][:,roi_1_sely]\n",
    "            vmin1 = np.percentile(roi_1, 5)\n",
    "            vmax1 = np.percentile(roi_1, 95)\n",
    "\n",
    "            ### ROI 2: \n",
    "            roi_2_lower_left = (dif.allBragg_coord_2[::-1][i] - dif.roisize).astype(int)\n",
    "            roi_2_upper_right = (dif.allBragg_coord_2[::-1][i] + dif.roisize).astype(int)\n",
    "            roi_2_selx  = np.arange(roi_2_lower_left[1],roi_2_upper_right[1])\n",
    "            roi_2_sely =  np.arange(roi_2_lower_left[0],roi_2_upper_right[0])\n",
    "            roi_2 = image[roi_2_selx,:][:,roi_2_sely]  - dif.bkg_img_fit[roi_2_selx,:][:,roi_2_sely]\n",
    "            vmin2 = np.percentile(roi_2, 5)\n",
    "            vmax2 = np.percentile(roi_2, 95)\n",
    "\n",
    "            ### Fit ROIs with a 2D gaussian: \n",
    "        #     def twoD_Gaussian(xx_yy, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "            initial_ax1=(roi_1.mean(axis = 0)[-1] - roi_1.mean(axis = 0)[1])/len(roi_1.mean(axis = 0))\n",
    "            initial_by1=(roi_1.mean(axis = 1)[-1] - roi_1.mean(axis = 1)[1])/len(roi_1.mean(axis = 1))\n",
    "            \n",
    "            initial_guess_1 = (1,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],7.5,7.5,0,vmin1,initial_ax1, initial_by1)\n",
    "            xx_yy_1 = (dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely])\n",
    "            popt_1, pcov_1 = opt.curve_fit(ued_dt.Gaussian_2D1_with_plane, xx_yy_1, roi_1.ravel(), p0=initial_guess_1)\n",
    "\n",
    "            initial_ax2 = (roi_2.mean(axis = 0)[-1] - roi_2.mean(axis = 0)[1])/len(roi_2.mean(axis = 0))\n",
    "            initial_by2 = (roi_2.mean(axis = 1)[-1] - roi_2.mean(axis = 1)[1])/len(roi_2.mean(axis = 1))\n",
    "            initial_guess_2 = (1,dif.allBragg_coord_2[::-1][i][0],dif.allBragg_coord_2[::-1][i][1],7.5,7.5,0,vmin2,initial_ax2, initial_by2)\n",
    "            xx_yy_2 = (dif.xx[roi_2_selx,:][:,roi_2_sely], dif.yy[roi_2_selx,:][:,roi_2_sely])\n",
    "            popt_2, pcov_2 = opt.curve_fit(ued_dt.Gaussian_2D1_with_plane, xx_yy_2, roi_2.ravel(), p0=initial_guess_2)\n",
    "\n",
    "            centers2[i]  = popt_1[1], popt_1[2]\n",
    "            centers2[::-1][i] = popt_2[1], popt_2[2]\n",
    "            \n",
    "#             print(popt_1)\n",
    "\n",
    "            dif.static.bragg_fits2[idx][i] =popt_1\n",
    "            dif.static.bragg_fits2[idx][::-1][i] = popt_2\n",
    "#             print(bragg_fits[idx][i])\n",
    "            \n",
    "            dif.static.fit_erros2[idx][i] = pcov_1\n",
    "            dif.static.fit_erros2[idx][::-1][i] = pcov_2\n",
    "\n",
    "\n",
    "        else:\n",
    "    #         print(f'nay nb: {i} and {np.arange(120)[::-1][i]}')\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.allBragg_indices_2[::-1][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = []\n",
    "fig, axs = plt.subplots(ncols = 5, figsize = (20,3))\n",
    "\n",
    "\n",
    "vmin = np.percentile(dif.first_image, 1)\n",
    "vmax = np.percentile(dif.first_image, 99)\n",
    "rect = patch.Rectangle(roi_1_lower_left, (roi_1_upper_right-roi_1_lower_left)[0], (roi_1_upper_right-roi_1_lower_left)[1] ,\n",
    "                      edgecolor = 'red',fill=False, lw=2 )\n",
    "im4 = axs[0].pcolormesh(dif.first_image, vmin = vmin, vmax = vmax)\n",
    "axs[0].scatter(roi_1_lower_left[0], roi_1_lower_left[1])\n",
    "axs[0].scatter(roi_1_upper_right[0], roi_1_upper_right[1])\n",
    "axs[0].add_patch(rect)\n",
    "axs[0].set_title('raw image')\n",
    "\n",
    "\n",
    "im0 = axs[1].pcolormesh(dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely], \n",
    "                        dif.bkg_img_fit[roi_1_selx,:][:,roi_1_sely])\n",
    "plt.colorbar(im0, ax=axs[1])\n",
    "axs[1].set_title('bkg_img_fit ROI')\n",
    "\n",
    "vmin = np.percentile(image[roi_1_selx,:][:,roi_1_sely], 5)\n",
    "vmax = np.percentile(image[roi_1_selx,:][:,roi_1_sely], 95)\n",
    "im1 = axs[2].pcolormesh(dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely],\n",
    "                        image[roi_1_selx,:][:,roi_1_sely], vmin= vmin, vmax = vmax)\n",
    "plt.colorbar(im1, ax=axs[2])\n",
    "axs[2].set_title('raw image ROI')\n",
    "\n",
    "vmin = np.percentile(image[roi_1_selx,:][:,roi_1_sely] - dif.bkg_img_fit[roi_1_selx,:][:,roi_1_sely], 5)\n",
    "vmax = np.percentile(image[roi_1_selx,:][:,roi_1_sely] - dif.bkg_img_fit[roi_1_selx,:][:,roi_1_sely], 95)\n",
    "im2 = axs[3].pcolormesh(dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely],\n",
    "                        image[roi_1_selx,:][:,roi_1_sely] - dif.bkg_img_fit[roi_1_selx,:][:,roi_1_sely], vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(im2, ax=axs[3])\n",
    "axs[3].set_title('image - bkg_img_fit')\n",
    "\n",
    "\n",
    "im3 = axs[4].pcolormesh(dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely],\n",
    "                        image[roi_1_selx,:][:,roi_1_sely] - dif.bkg_img_bkg[roi_1_selx,:][:,roi_1_sely], vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(im3, ax=axs[4])\n",
    "axs[4].set_title('image - bkg_img_bkg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lmfit\n",
    "# from lmfit import Model, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ued_dt.Gaussian_2D1_with_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.dmodel_bragg = Model(ued_dt.Gaussian_2D1_with_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_bragg_t0 = Parameters()\n",
    "# # (amp0_1, x0_1, y0_1, sigmax_1, sigmay_1,theta0_1, offset0_1, initial_ax_1, initial_by_1)\n",
    "# params_bragg_t0.add('amplitude', value=amp0_1)\n",
    "# params_bragg_t0.add('xo', value=x0_1)\n",
    "# params_bragg_t0.add('yo', value=y0_1)\n",
    "# params_bragg_t0.add('sigma_x', value=sigmax_1)\n",
    "# params_bragg_t0.add('sigma_y', value=sigmay_1)\n",
    "# params_bragg_t0.add('theta', value=theta0_1)\n",
    "# params_bragg_t0.add('offset', value=offset0_1)\n",
    "# params_bragg_t0.add('ax', value=initial_ax_1)\n",
    "# params_bragg_t0.add('by', value=initial_by_1)\n",
    "\n",
    "# # fit(y, params, x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_tmp = dif.dmodel_bragg.fit(roi_1.ravel(), params_bragg_t0, xx_yy=xx_yy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_bragg(xx_yy,\n",
    "#     amplitude,\n",
    "#     xo,\n",
    "#     yo,\n",
    "#     sigma_x,\n",
    "#     sigma_y,\n",
    "#     theta,\n",
    "#     offset,\n",
    "#     ax,\n",
    "#     by,\n",
    "# )\n",
    "# #     hkl = dif.compact_hkl[good_bragg_fit_mask]\n",
    "# #     Bfe  = BFE0 + Dfe\n",
    "# #     Bpt  = BPT0 + Dpt\n",
    "#     return ued_dt.Gaussian_2D1_with_plane\n",
    "# dif.model_bragg = model_func\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# params = Parameters()\n",
    "\n",
    "# params_bragg.add('Dfe', value=dif.Bfe_time_test_warren_glob[-1]-dif.Bfe_time_test_warren_glob[0])\n",
    "# params_bragg.add('Dpt', value=dif.Bpt_time_test_warren_glob[-1]-dif.Bpt_time_test_warren_glob[0])\n",
    "# params_bragg.add('BFE0', value=dif.Bfe_time_test_warren_glob[0], vary=False)\n",
    "# params_bragg.add('BPT0', value=dif.Bpt_time_test_warren_glob[0], vary=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dif.lmfit_results = dict()\n",
    "# for t_idx in np.arange(len(dif.bincenters)):\n",
    "#     small_y = y_fit_all[t_idx,:]\n",
    "#     small_q = dif.q_symmetrised_compact[:,:][good_bragg_fit_mask].T[t_idx,:]\n",
    "#     result = dif.dmodel.fit(small_y, params, q=small_q, weights = np.sqrt(tmp_a0) )\n",
    "# #     result = dif.dmodel.fit(small_y, params, q=small_q,nan_policy='propagate' )\n",
    "# #     result = dif.dmodel.fit(small_y, params, q=small_q, )\n",
    "#     dif.lmfit_results[t_idx] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, j in enumerate(np.arange(0,dif.max_frame,dif.frame_step)):\n",
    "    print(idx, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(dif.first_image.shape[0])\n",
    "# y = np.arange(dif.first_image.shape[1])\n",
    "# xx, yy = np.meshgrid(x,y)\n",
    "\n",
    "dif.static.bragg_fits3 = np.zeros((10, 120, 9))\n",
    "dif.static.fit_erros3 = np.zeros((10, 120, 9,9))\n",
    "\n",
    "for idx, j in enumerate(np.arange(0,dif.max_frame,dif.frame_step)):\n",
    "    print(idx, j)\n",
    "    image = dif.load_img(dif.fnames[sel_pre_t0[0][j:j+(dif.frame_step-1)]])\n",
    "#     image = ued_dt.despike(image)\n",
    "    image /= image[sel_corners].mean()\n",
    "#     image /= image[dif.donut_mask].mean()\n",
    "\n",
    "#     image = image - empty_img2\n",
    "    for i in np.arange(len(dif.allBragg_names_1)//2): \n",
    "#     for i in np.arange(len(dif.allBragg_names_1)):\n",
    "        if (dif.sel_bragg_in_im[i]&dif.sel_bragg_in_im[::-1][i]):\n",
    "\n",
    "            ### ROI 1: \n",
    "            roi_1_lower_left = (dif.allBragg_coord_2[i] - dif.roisize).astype(int)\n",
    "            roi_1_upper_right = (dif.allBragg_coord_2[i] + dif.roisize).astype(int)\n",
    "            roi_1_selx  = np.arange(roi_1_lower_left[1],roi_1_upper_right[1])\n",
    "            roi_1_sely =  np.arange(roi_1_lower_left[0],roi_1_upper_right[0])\n",
    "            roi_1 = image[roi_1_selx,:][:,roi_1_sely] - dif.bkg_img_bkg[roi_1_selx,:][:,roi_1_sely]\n",
    "            \n",
    "            ### ROI 2: \n",
    "            roi_2_lower_left = (dif.allBragg_coord_2[::-1][i] - dif.roisize).astype(int)\n",
    "            roi_2_upper_right = (dif.allBragg_coord_2[::-1][i] + dif.roisize).astype(int)\n",
    "            roi_2_selx  = np.arange(roi_2_lower_left[1],roi_2_upper_right[1])\n",
    "            roi_2_sely =  np.arange(roi_2_lower_left[0],roi_2_upper_right[0])\n",
    "            roi_2 = image[roi_2_selx,:][:,roi_2_sely] - dif.bkg_img_bkg[roi_2_selx,:][:,roi_2_sely]\n",
    "\n",
    "            ### Fit ROIs with a 2D gaussian: \n",
    "        #     def twoD_Gaussian(xx_yy, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "        \n",
    "            \n",
    "            \n",
    "#             int(sp.ndimage.center_of_mass(roi_1)[0]), int(sp.ndimage.center_of_mass(roi_1)[1])\n",
    "#             initial_guess_1 = (2,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],6.7,6.7,0, np.min(roi_1), initial_ax1, initial_by1)\n",
    "            ### ROI 1 \n",
    "\n",
    "            xx_yy_1 = (dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely])\n",
    "            tmp_hist_1, tmp_bins_1= np.histogram(roi_1, bins = 100)\n",
    "            tmp_hist_norm_1, tmp_bins_norm_1= np.histogram(roi_1, bins = 100, normed = True )\n",
    "            tmp_bins_norm_1 = tmp_bins_norm_1[1:]\n",
    "            threshold_1 = tmp_bins_norm_1[np.cumsum(tmp_hist_norm_1) * (tmp_bins_norm_1[1] - tmp_bins_norm_1[0]) > 0.99][0]\n",
    "            mnorm2d_1 = np.ma.masked_less(roi_1,threshold_1)\n",
    "            com_1 = sp.ndimage.center_of_mass(mnorm2d_1)\n",
    "            print(com_1)\n",
    "            \n",
    "            if (roi_1.shape[0] < com_1[0])or(roi_1.shape[1] < com_1[1])or(roi_1.shape[0] <0)or(roi_1.shape[1] <0):\n",
    "                print('center of mass outside the image')\n",
    "                print(i)\n",
    "            \n",
    "            offset0_1 = np.nanmean(tmp_bins_1[1:][5:10])\n",
    "            amp0_1 = np.nanmean(tmp_bins_1[1:][80:90]) - np.nanmean(tmp_bins_1[1:][5:10]) # amplitude\n",
    "            x0_1 = xx_yy_1[0][int(com_1[0]), int(com_1[1])] \n",
    "            y0_1 = xx_yy_1[1][int(com_1[0]), int(com_1[1])]\n",
    "            sigmax_1, sigmay_1 = 6.7, 6.7\n",
    "            theta0_1 = 0\n",
    "\n",
    "            initial_ax_1=(roi_1.mean(axis = 0)[-1] - roi_1.mean(axis = 0)[1])/len(roi_1.mean(axis = 0))\n",
    "            initial_by_1=(roi_1.mean(axis = 1)[-1] - roi_1.mean(axis = 1)[1])/len(roi_1.mean(axis = 1))\n",
    "#             initial_guess_1 = (2,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],6.7,6.7,0, np.min(roi_1), initial_ax_1, initial_by_1)\n",
    "#             initial_guess_1 = (amp0_1, x0_1, y0_1, sigmax_1, sigmay_1,theta0_1, offset0_1, initial_ax_1, initial_by_1)\n",
    "            # FIT !                         \n",
    "            params_bragg_t0_1 = Parameters()\n",
    "            # (amp0_1, x0_1, y0_1, sigmax_1, sigmay_1,theta0_1, offset0_1, initial_ax_1, initial_by_1)\n",
    "            params_bragg_t0_1.add('amplitude', value=amp0_1)\n",
    "            params_bragg_t0_1.add('xo', value=x0_1)\n",
    "            params_bragg_t0_1.add('yo', value=y0_1)\n",
    "            params_bragg_t0_1.add('sigma_x', value=sigmax_1)\n",
    "            params_bragg_t0_1.add('sigma_y', value=sigmay_1)\n",
    "            params_bragg_t0_1.add('theta', value=theta0_1)\n",
    "            params_bragg_t0_1.add('offset', value=offset0_1)\n",
    "            params_bragg_t0_1.add('ax', value=initial_ax_1)\n",
    "            params_bragg_t0_1.add('by', value=initial_by_1)\n",
    "            \n",
    "            result_tmp_1 = dif.dmodel_bragg.fit(roi_1.ravel(), params_bragg_t0_1, xx_yy=xx_yy_1)\n",
    "#             print(result_tmp.best_values)\n",
    "            pcov_1 = result_tmp_1.covar\n",
    "            popt_1 = result_tmp_1.best_values['amplitude'], result_tmp_1.best_values['xo'], result_tmp_1.best_values['yo'], result_tmp_1.best_values['sigma_x'], result_tmp_1.best_values['sigma_y'], result_tmp_1.best_values['theta'], result_tmp_1.best_values['offset'], result_tmp_1.best_values['ax'], result_tmp_1.best_values['by'] \n",
    "            \n",
    "#             popt_1, pcov_1 = opt.curve_fit(ued_dt.Gaussian_2D1_with_plane, xx_yy_1, roi_1.ravel(), p0=initial_guess_1)\n",
    "                                   \n",
    "                                   \n",
    "\n",
    "            xx_yy_2 = (dif.xx[roi_2_selx,:][:,roi_2_sely], dif.yy[roi_2_selx,:][:,roi_2_sely])\n",
    "            tmp_hist_2, tmp_bins_2= np.histogram(roi_2, bins = 100)\n",
    "            tmp_hist_norm_2, tmp_bins_norm_2= np.histogram(roi_2, bins = 100, normed = True )\n",
    "            tmp_bins_norm_2 = tmp_bins_norm_2[1:]\n",
    "            threshold_2 = tmp_bins_norm_2[np.cumsum(tmp_hist_norm_2) * (tmp_bins_norm_2[1] - tmp_bins_norm_2[0]) > 0.99][0]\n",
    "            mnorm2d_2 = np.ma.masked_less(roi_2,threshold_2)\n",
    "            com_2 = sp.ndimage.center_of_mass(mnorm2d_2)\n",
    "            print(com_2)\n",
    "            \n",
    "            if (roi_2.shape[0] < com_2[0])or(roi_2.shape[1] < com_2[1])or(roi_2.shape[0] <0)or(roi_2.shape[1] <0):\n",
    "                print('center of mass outside the image')\n",
    "                print(i)\n",
    "            \n",
    "            offset0_2 = np.nanmean(tmp_bins_2[1:][5:10])\n",
    "            amp0_2 = np.nanmean(tmp_bins_2[1:][80:90]) - np.nanmean(tmp_bins_2[1:][5:10]) # amplitude\n",
    "            x0_2 = xx_yy_2[0][int(com_2[0]), int(com_2[1])] \n",
    "            y0_2 = xx_yy_2[1][int(com_2[0]), int(com_2[1])]\n",
    "            sigmax_2, sigmay_2 = 6.7, 6.7\n",
    "            theta0_2 = 0\n",
    "\n",
    "            initial_ax_2=(roi_2.mean(axis = 0)[-1] - roi_2.mean(axis = 0)[1])/len(roi_2.mean(axis = 0))\n",
    "            initial_by_2=(roi_2.mean(axis = 1)[-1] - roi_2.mean(axis = 1)[1])/len(roi_2.mean(axis = 1))\n",
    "#             initial_guess_1 = (2,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],6.7,6.7,0, np.min(roi_1), initial_ax_1, initial_by_1)\n",
    "            initial_guess_2 = (amp0_2, x0_2, y0_2, sigmax_2, sigmay_2,theta0_2, offset0_2, initial_ax_2, initial_by_2)\n",
    "\n",
    "            params_bragg_t0_2 = Parameters()\n",
    "            # (amp0_1, x0_1, y0_1, sigmax_1, sigmay_1,theta0_1, offset0_1, initial_ax_1, initial_by_1)\n",
    "            params_bragg_t0_2.add('amplitude', value=amp0_2)\n",
    "            params_bragg_t0_2.add('xo', value=x0_2)\n",
    "            params_bragg_t0_2.add('yo', value=y0_2)\n",
    "            params_bragg_t0_2.add('sigma_x', value=sigmax_2)\n",
    "            params_bragg_t0_2.add('sigma_y', value=sigmay_2)\n",
    "            params_bragg_t0_2.add('theta', value=theta0_2)\n",
    "            params_bragg_t0_2.add('offset', value=offset0_2)\n",
    "            params_bragg_t0_2.add('ax', value=initial_ax_2)\n",
    "            params_bragg_t0_2.add('by', value=initial_by_2)\n",
    "            \n",
    "            result_tmp_2 = dif.dmodel_bragg.fit(roi_2.ravel(), params_bragg_t0_2, xx_yy=xx_yy_2)\n",
    "#             print(result_tmp.best_values)\n",
    "            pcov_2 = result_tmp_2.covar\n",
    "            popt_2 = result_tmp_2.best_values['amplitude'], result_tmp_2.best_values['xo'], result_tmp_2.best_values['yo'], result_tmp_2.best_values['sigma_x'], result_tmp_2.best_values['sigma_y'], result_tmp_2.best_values['theta'], result_tmp_2.best_values['offset'], result_tmp_2.best_values['ax'], result_tmp_2.best_values['by'] \n",
    "\n",
    "\n",
    "#             popt_2, pcov_2 = opt.curve_fit(ued_dt.Gaussian_2D1_with_plane, xx_yy_2, roi_2.ravel(), p0=initial_guess_2)\n",
    "            \n",
    "            dif.static.bragg_fits3[idx][i] =popt_1\n",
    "            dif.static.bragg_fits3[idx][::-1][i] = popt_2\n",
    "            \n",
    "            dif.static.fit_erros3[idx][i] = pcov_1\n",
    "            dif.static.fit_erros3[idx][::-1][i] = pcov_2\n",
    "\n",
    "        else:\n",
    "#             print(f'nay nb: {i} and {np.arange(120)[::-1][i]}')\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i=59 \n",
    "# i=119\n",
    "# i=49\n",
    "\n",
    "\n",
    "# i=53\n",
    "# i=6\n",
    "# i=48\n",
    "# print(sel_bragg_in_im[i])\n",
    "\n",
    "j= 3\n",
    "i= np.arange(len(dif.sel_bragg_in_im))[dif.sel_bragg_in_im][j]\n",
    "print(i)\n",
    "\n",
    "\n",
    "\n",
    "print('Bragg in img ? ')\n",
    "print(dif.sel_bragg_in_im[i])\n",
    "image = dif.load_img(dif.fnames[sel_pre_t0[0][j:j+24]])\n",
    "image = ued_dt.despike(image)\n",
    "# image /= image[sel_corners].mean()\n",
    "image = image \n",
    "# image /= image[dif.donut_mask].mean()\n",
    "image /= image[sel_corners].mean()\n",
    "\n",
    "roi_1_lower_left = (dif.allBragg_coord_2[i] - dif.roisize).astype(int)\n",
    "roi_1_upper_right = (dif.allBragg_coord_2[i] + dif.roisize).astype(int)\n",
    "roi_1_selx  = np.arange(roi_1_lower_left[1],roi_1_upper_right[1])\n",
    "roi_1_sely =  np.arange(roi_1_lower_left[0],roi_1_upper_right[0])\n",
    "roi_1 = image[roi_1_selx,:][:,roi_1_sely] - dif.bkg_img_bkg[roi_1_selx,:][:,roi_1_sely]\n",
    "\n",
    "xx_yy_1 = (dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely])\n",
    "\n",
    "\n",
    "xx_yy_1 = (dif.xx[roi_1_selx,:][:,roi_1_sely], dif.yy[roi_1_selx,:][:,roi_1_sely])\n",
    "tmp_hist_1, tmp_bins_1= np.histogram(roi_1, bins = 100)\n",
    "tmp_hist_norm_1, tmp_bins_norm_1= np.histogram(roi_1, bins = 100, normed = True )\n",
    "tmp_bins_norm_1 = tmp_bins_norm_1[1:]\n",
    "threshold_1 = tmp_bins_norm_1[np.cumsum(tmp_hist_norm_1) * (tmp_bins_norm_1[1] - tmp_bins_norm_1[0]) > 0.99][0]\n",
    "mnorm2d_1 = np.ma.masked_less(roi_1,threshold_1)\n",
    "\n",
    "com_1 = sp.ndimage.center_of_mass(mnorm2d_1)\n",
    "\n",
    "\n",
    "offset0_1 = np.nanmean(tmp_bins_1[1:][5:10])\n",
    "amp0_1 = np.nanmean(tmp_bins_1[1:][80:90]) - np.nanmean(tmp_bins_1[1:][5:10]) # amplitude\n",
    "x0_1 = xx_yy_1[0][int(com_1[0]), int(com_1[1])] \n",
    "y0_1 = xx_yy_1[1][int(com_1[0]), int(com_1[1])]\n",
    "sigmax_1, sigmay_1 = 6.7, 6.7\n",
    "theta0_1 = 0\n",
    "\n",
    "initial_ax_1=(roi_1.mean(axis = 0)[-1] - roi_1.mean(axis = 0)[1])/len(roi_1.mean(axis = 0))\n",
    "initial_by_1=(roi_1.mean(axis = 1)[-1] - roi_1.mean(axis = 1)[1])/len(roi_1.mean(axis = 1))\n",
    "#             initial_guess_1 = (2,dif.allBragg_coord_2[i][0],dif.allBragg_coord_2[i][1],6.7,6.7,0, np.min(roi_1), initial_ax_1, initial_by_1)\n",
    "initial_guess_1 = (amp0_1, x0_1, y0_1, sigmax_1, sigmay_1,theta0_1, offset0_1, initial_ax_1, initial_by_1)\n",
    "ppot_tmp, pcov_tmp = opt.curve_fit(ued_dt.Gaussian_2D1_with_plane, xx_yy_1, roi_1.ravel(), p0=initial_guess_1)\n",
    "\n",
    "axs = []\n",
    "fig, axs = plt.subplots(ncols= 3, nrows = 2, figsize = (16/1.,8/1.))\n",
    "# ppot_tmp .\n",
    "gauss_img = ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *dif.static.bragg_fits3[0][i]).reshape(dif.roisize*2,dif.roisize*2)\n",
    "# gauss_img = ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *initial_guess_1).reshape(dif.roisize*2,dif.roisize*2)\n",
    "# gauss_img = ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *ppot_tmp).reshape(dif.roisize*2,dif.roisize*2)\n",
    "print('bragg fits 3:')\n",
    "print(dif.static.bragg_fits3[0][i])\n",
    "print('popt:')\n",
    "print(ppot_tmp)\n",
    "\n",
    "vmin = np.percentile(roi_1, 0)\n",
    "vmax = np.percentile(roi_1, 100)\n",
    "\n",
    "im0 = axs[0,0].pcolormesh(xx_yy_1[0], xx_yy_1[1],roi_1, vmin=vmin, vmax=vmax)\n",
    "im1 = axs[0,1].pcolormesh(xx_yy_1[0], xx_yy_1[1], ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *dif.static.bragg_fits3[0][i]).reshape(dif.roisize*2,dif.roisize*2), vmin=vmin, vmax=vmax )\n",
    "# plt.colorbar(im0, ax=axs[1])\n",
    "\n",
    "\n",
    "vmin = np.percentile(roi_1 - ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *dif.static.bragg_fits3[0][i]).reshape(dif.roisize*2,dif.roisize*2), 0)\n",
    "vmax = np.percentile(roi_1 - ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *dif.static.bragg_fits3[0][i]).reshape(dif.roisize*2,dif.roisize*2), 100)\n",
    "vmax = np.max((np.abs(vmin), vmax))\n",
    "\n",
    "im2 = axs[0,2].pcolormesh(xx_yy_1[0], xx_yy_1[1],roi_1 - ued_dt.Gaussian_2D1_with_plane(xx_yy_1, *dif.static.bragg_fits3[0][i]).reshape(dif.roisize*2,dif.roisize*2),cmap='seismic', vmin=-vmax, vmax=vmax )\n",
    "\n",
    "plt.colorbar(im0, ax=axs[0,0])\n",
    "plt.colorbar(im1, ax=axs[0,1])\n",
    "plt.colorbar(im2, ax=axs[0,2])\n",
    "\n",
    "\n",
    "axs[0, 0].set_title(f'exp: {dif.allBragg_indices_2[i]} peak')\n",
    "axs[0, 1].set_title(f'2D Gaussian Fit')\n",
    "axs[0, 2].set_title(f'difference empty_img2')\n",
    "\n",
    "\n",
    "\n",
    "vmin = np.percentile(dif.first_image, 0)\n",
    "vmax = np.percentile(dif.first_image, 80)\n",
    "rect = patch.Rectangle(roi_1_lower_left, (roi_1_upper_right-roi_1_lower_left)[0], (roi_1_upper_right-roi_1_lower_left)[1] ,\n",
    "                      edgecolor = 'red',fill=False, lw=2 )\n",
    "im4 = axs[1,2].pcolormesh(np.log(dif.first_image), )\n",
    "axs[1,2].add_patch(rect)\n",
    "plt.colorbar(im4, ax=axs[1,2])\n",
    "\n",
    "axs[1, 0].plot(dif.xx[roi_1_selx,:][:,roi_1_sely][0], roi_1[38-1:38+1,:].mean(axis=0), label = 'img - bkg')\n",
    "axs[1, 0].plot(dif.xx[roi_1_selx,:][:,roi_1_sely][0], gauss_img[38-1:38+1,:].mean(axis=0), '--', label = 'fit over x')\n",
    "axs[1, 0].plot(dif.xx[roi_1_selx,:][:,roi_1_sely][0], np.min(gauss_img[38-1:38+1,:].mean(axis=0)) + roi_1[38-1:38+1,:].mean(axis=0) - gauss_img[38-1:38+1,:].mean(axis=0), c= 'r', label = 'difference + min') \n",
    "axs[1, 0].axhline(np.min(gauss_img[38-1:38+1,:].mean(axis=0)) + 0 , c= 'k', ls='--', alpha = 0.3)\n",
    "axs[1, 0].legend(frameon = False)\n",
    "\n",
    "axs[1, 1].plot(dif.yy[roi_1_selx,:][:,roi_1_sely][:,0], roi_1[:,40-1:40+1].mean(axis = 1), label = 'img - bkg (Y)')\n",
    "axs[1, 1].plot(dif.yy[roi_1_selx,:][:,roi_1_sely][:,0], gauss_img[:,40-1:40+1].mean(axis = 1), '--', label = 'fit over y')\n",
    "axs[1, 1].plot(dif.yy[roi_1_selx,:][:,roi_1_sely][:,0], np.min(gauss_img[:,40-1:40+1].mean(axis = 1)) + roi_1[:,40-1:40+1].mean(axis=1) - gauss_img[:,40-1:40+1].mean(axis=1), c= 'r', label = 'difference + min') \n",
    "axs[1, 1].axhline(np.min(gauss_img[:,40-1:40+1].mean(axis = 1)) +0, c= 'k', ls='--', alpha = 0.3)\n",
    "axs[1, 1].legend(frameon = False)\n",
    "axs[0,0].axvline(xx_yy_1[0][0,40])\n",
    "axs[0,0].axhline(xx_yy_1[1][40,0])\n",
    "plt.colorbar(im0, ax=axs[1,0])\n",
    "plt.colorbar(im1, ax=axs[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppot_tmp\n",
    "# pcov_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for image center drift with fitting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the bragg spot positions fitted with the 2D Gaussian to find the average center of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "avg_fit = (0.5*(dif.static.bragg_fits2[i, ::-1, :] + dif.static.bragg_fits2[i,:,:]))[dif.sel_bragg_in_im][:-1]\n",
    "test_sel = np.where((avg_fit[:,2] != 0.)&(avg_fit[:,1] != 0.))\n",
    "\n",
    "\n",
    "cent_test2 = np.zeros((int(dif.max_frame/dif.frame_step),2))\n",
    "for i in np.arange(int(dif.max_frame/dif.frame_step)):\n",
    "    \n",
    "    avg_fit = (0.5*(dif.static.bragg_fits2[i, ::-1, :] + dif.static.bragg_fits2[i,:,:]))[dif.sel_bragg_in_im][:-1]\n",
    "    test_sel = np.where((avg_fit[:,2] != 0.)&(avg_fit[:,1] != 0.))\n",
    "    \n",
    "    cent_test2[i] = avg_fit[test_sel, 1:3].mean(axis = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "\n",
    "# i=0\n",
    "avg_fit = (0.5*(dif.static.bragg_fits2[i, ::-1, :] + dif.static.bragg_fits2[i,:,:]))[dif.sel_bragg_in_im][:-1]\n",
    "test_sel = np.where((avg_fit[:,2] != 0.)&(avg_fit[:,1] != 0.))\n",
    "\n",
    "plt.plot(avg_fit[test_sel,1], \n",
    "            avg_fit[test_sel,2], '.', color=f'C{i}')\n",
    "plt.scatter(cent_test2[i][0],cent_test2[i][1], color=f'r', s=75, zorder=100)\n",
    "plt.scatter(dif.centerpos[0], dif.centerpos[1], color='k',zorder=100, s=75)\n",
    "\n",
    "plt.xlabel('x pos (px)')\n",
    "plt.ylabel('y pos (px)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Time Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and actual binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a couple of minutes ... \n",
    "\n",
    "dif.i0_params = np.zeros((len(dif.fnames_I0),6))\n",
    "\n",
    "for idx, fname_I0 in enumerate(dif.fnames_I0):\n",
    "    dif.i0_params[idx] = ued_dt.load_and_fit_i0(fname_I0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.sqrt( (dif.i0_params[:,1] - np.mean(dif.i0_params[:,1]))**2 + (dif.i0_params[:,2] - np.mean(dif.i0_params[:,2]))**2 ) )\n",
    "plt.axhline(np.std(np.sqrt( (dif.i0_params[:,1] - np.mean(dif.i0_params[:,1]))**2 + (dif.i0_params[:,2] - np.mean(dif.i0_params[:,2]))**2 ))*5, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.bin_delays(precission=0.1, filter_with_i0 = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dif.bin_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Binned data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# here is how I save it\n",
    "with open('test_save_binned_data/saved_dif3.pkl', 'wb') as f:\n",
    "    pickle.dump(dif, f)\n",
    "\n",
    "# And here is how I would load it\n",
    "# with open('saved_dictionary.pkl', 'rb') as f:\n",
    "#     loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: Lattice Expansion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diegos_bizzare_adventure_Phantom_Blood",
   "language": "python",
   "name": "diegos_bizzare_adventure_phantom_blood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "state": {
    "7ec6e54a6cdb44b382fd15de54c72d39": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "b85d3707bfad4691bfb44a44f36984d2": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "c8e0052ca6744382a6e29f604fcb30b2": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "dd25ca78551e4595963b45e5662cb3d1": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
